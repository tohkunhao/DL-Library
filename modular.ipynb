{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modular.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxPF1e1EWVhcYfTapDSUWd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tohkunhao/DL-Library/blob/main/modular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1nHrepTlxWA"
      },
      "source": [
        "import GPUtil\n",
        "import numpy as np\n",
        "import cupy as cp"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9QwhIYgp4xa"
      },
      "source": [
        "def CheckGPU():\n",
        "  try:\n",
        "    GPUtil.getAvailable()\n",
        "    status=\"available\"\n",
        "  except:\n",
        "    status=\"not available\"\n",
        "  \n",
        "  return status\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CxhcIRTbqo40",
        "outputId": "cc6aa72c-66d4-4de9-938a-3f3e4c1e0b42"
      },
      "source": [
        "class Linear():\n",
        "  '''\n",
        "  takes in the arguments (in_channels, out_channels, init_type, bias)\n",
        "  in_channels is the number of input features\n",
        "  out_channels is the number of perceptrons\n",
        "  init_type is the type of weight initialisations. Default is He Kaiming's for use with ReLU\n",
        "    other options include Xavier for tanh\n",
        "  bias determines if bias is used. Default is set to true\n",
        "  '''\n",
        "  def __init__(self, in_channels, out_channels, init_type='He',bias=True):\n",
        "    self.in_channels= in_channels\n",
        "    self.out_channels=out_channels\n",
        "    self.init_type=init_type\n",
        "    self.params={} #dict to contain the model parameters\n",
        "    self.grads={} #dict to contain the gradients\n",
        "    self.bias=bias\n",
        "  \n",
        "  def forward(self,x):\n",
        "    xp=cp.get_array_module(x)\n",
        "    self.x=x #store x for use in backprop\n",
        "\n",
        "    if self.init_type= 'He':\n",
        "      sd=xp.sqrt(2/in_channels)\n",
        "    elif self.init_type='Xavier':\n",
        "      sd=xp.sqrt(1/in_channels)\n",
        "\n",
        "    self.params['w']=xp.random.rand(self.in_channels,self.out_channels)*sd\n",
        "\n",
        "    if self.bias:\n",
        "      self.params['b']=xp.zeros((1,self.out_channels))\n",
        "      out=xp.dot(x,self.params['w'])+self.params['b']\n",
        "    else:\n",
        "      out=xp.dot(x,self.params['w'])\n",
        "    \n",
        "    return out\n",
        "\n",
        "  \n",
        "  def backward(self,dout):\n",
        "    xp=cp.get_array_module(dout)\n",
        "\n",
        "    if self.bias:\n",
        "      self.grads['db']=xp.sum(dout,axis=0)\n",
        "    \n",
        "    self.grads['dw']=xp.dot(xp.transpose(self.x),dout)\n",
        "\n",
        "    return xp.dot(dout,xp.transpose(self.params['w']))\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'not available'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}